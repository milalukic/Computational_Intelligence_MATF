{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807ad9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96b9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, gradient, x0, alpha, eps, iters):\n",
    "    x = x0\n",
    "    for i in range(iters):\n",
    "        x_new = x - alpha * gradient(x)\n",
    "\n",
    "        if abs(f(x_new) - f(x)) < eps:\n",
    "            break\n",
    "\n",
    "        x = x_new\n",
    "        \n",
    "    result = {}\n",
    "    result['converged'] = i != iters\n",
    "    result['num_iters'] = i\n",
    "    result['x'] = x_new\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef22193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.5*(x[0]**2 + 10*x[1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482845fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x):\n",
    "    return np.array([x[0], 10*x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "299d139d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True, 'num_iters': 54, 'x': array([0.00912976, 0.        ])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.array([3,4])\n",
    "eps = 0.00001\n",
    "iters = 1000\n",
    "alpha = 0.1\n",
    "\n",
    "gradient_descent(f, gradient, x0, alpha, eps, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d62bfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(f, gradient, x0, alpha, eps, iters, beta):\n",
    "    x=x0\n",
    "    d = 0\n",
    "    \n",
    "    for i in range(iters):\n",
    "        d = beta*d - alpha*gradient(x)\n",
    "        x_new = x + d\n",
    "        \n",
    "        if abs(f(x_new) - f(x)) < eps:\n",
    "            break\n",
    "            \n",
    "        x = x_new\n",
    "    \n",
    "    result = {}\n",
    "    result['converged'] = i != iters\n",
    "    result['num_iters'] = i\n",
    "    result['x'] = x_new\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8497bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True, 'num_iters': 126, 'x': array([-0.00372751,  0.00300256])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momentum(f, gradient, x0, alpha, eps, iters, beta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bb39d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(f, gradient, x0, alpha, eps, iters, beta):\n",
    "    x=x0\n",
    "    d = 0\n",
    "    \n",
    "    for i in range(iters):\n",
    "        d = beta*d - alpha*gradient(x - beta*d)\n",
    "        x_new = x + d\n",
    "        \n",
    "        if abs(f(x_new) - f(x)) < eps:\n",
    "            break\n",
    "            \n",
    "        x = x_new\n",
    "    \n",
    "    result = {}\n",
    "    result['converged'] = i != iters\n",
    "    result['num_iters'] = i\n",
    "    result['x'] = x_new\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a20e40d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True,\n",
       " 'num_iters': 999,\n",
       " 'x': array([-7.79871912e-003,  1.98559672e+128])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nesterov(f, gradient, x0, alpha, eps, iters, beta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "442608af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(f, gradient, x0, alpha, eps, iters, beta1, beta2):\n",
    "    result = {}\n",
    "    x = x0\n",
    "    m = 0\n",
    "    v = 0\n",
    "    \n",
    "    for i in range(iters):\n",
    "        grad = gradient(x)\n",
    "        m = beta1*m + (1-beta1)*grad\n",
    "        v = beta2*v + (1-beta2)*grad**2\n",
    "        \n",
    "        m_hat = m/(1-beta1**i)\n",
    "        v_hat = v/(1-beta2**i)\n",
    "        \n",
    "        x_new = x - alpha*m_hat / (np.sqrt(v_hat) + eps)\n",
    "        \n",
    "\n",
    "        if abs(f(x_new) - f(x)) < eps:\n",
    "            result['converged'] = True\n",
    "            break\n",
    "        x = x_new\n",
    "        \n",
    "    if 'converged' not in result:\n",
    "        result['converged'] = False\n",
    "        result['iter'] = i\n",
    "        result['x'] = x\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3ad9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mila\\AppData\\Local\\Temp\\ipykernel_9068\\1813489047.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "  m_hat = m/(1-beta1**i)\n",
      "C:\\Users\\Mila\\AppData\\Local\\Temp\\ipykernel_9068\\1813489047.py:13: RuntimeWarning: divide by zero encountered in divide\n",
      "  v_hat = v/(1-beta2**i)\n",
      "C:\\Users\\Mila\\AppData\\Local\\Temp\\ipykernel_9068\\1813489047.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  x_new = x - alpha*m_hat / (np.sqrt(v_hat) + eps)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'converged': False, 'iter': 999, 'x': array([nan, nan])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam(x0=x0,\n",
    "     f=f,\n",
    "     gradient=gradient,\n",
    "     alpha=0.5, # u stvarnim primenama bi alpha bilo mnogo manje, npr. 0.001\n",
    "     iters=1000,\n",
    "     beta1=0.9,\n",
    "     beta2=0.999,\n",
    "     eps=1e-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
